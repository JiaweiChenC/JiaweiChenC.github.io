<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Jiawei Chen</title>
        <link>/</link>
        <description>This is my cool site</description>
        <generator>Hugo -- gohugo.io</generator><managingEditor>jc5667@columbia.edu (Jiawei Chen)</managingEditor>
            <webMaster>jc5667@columbia.edu (Jiawei Chen)</webMaster><lastBuildDate>Mon, 12 Sep 2022 01:55:00 -0400</lastBuildDate>
            <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>Evolving a soft robot</title>
    <link>/posts/ea/</link>
    <pubDate>Fri, 19 Aug 2022 23:52:39 -0400</pubDate>
    <author>Jiawei Chen</author>
    <guid>/posts/ea/</guid>
    <description><![CDATA[<p>Let&rsquo;s see who is the fastest soft robot :).</p>]]></description>
</item>
<item>
    <title>Hermite Matrix</title>
    <link>/posts/20220910145601-hermite_matrix/</link>
    <pubDate>Fri, 19 Aug 2022 23:52:39 -0400</pubDate>
    <author>Jiawei Chen</author>
    <guid>/posts/20220910145601-hermite_matrix/</guid>
    <description><![CDATA[Hermite Matrix Definition In mathematics, a Hermitian matrix(or self-joint matrix) is a complex square matrix that is equal to its own conjugate transpose - that is, the element in the i-th row and j-th column is equal to the complex conjugate of the element in the j-th row and i-th column, for all indices i and j: \[ a_{i j}=\overline{a_{j i}} \] or in matrix form \[ A=\overline{A^{\top}} \] Hermitian matrices can be understood as the complex extension of real symmetric matrices If a conjugate transpose of a matrix A is denoted by \(A^H\), then the Hermitian property can be written concisely as \[ A = A^{H} \] Other equivalent notations in common use are \[ A^{\mathrm{H}}=A^{\dagger}=A^{*} \]]]></description>
</item>
<item>
    <title>My Emacs</title>
    <link>/posts/emacs/emacs/</link>
    <pubDate>Fri, 19 Aug 2022 23:52:39 -0400</pubDate>
    <author>Jiawei Chen</author>
    <guid>/posts/emacs/emacs/</guid>
    <description><![CDATA[<p>Do everything with Emacs</p>]]></description>
</item>
<item>
    <title>NP problem</title>
    <link>/posts/20220622111616-np_problem/</link>
    <pubDate>Fri, 19 Aug 2022 23:52:39 -0400</pubDate>
    <author>Jiawei Chen</author>
    <guid>/posts/20220622111616-np_problem/</guid>
    <description><![CDATA[P, NP, NP-complete problem Figure 1: NP problem
P A set of problems that can be solved by a deterministic Turing machine in polynomial-time.
NP The NP problems is a set of decision problems that can be solved by a Non-deterministic Turing Machine in polynomial-time, P is a subset of NP(any problem that can be solved by a deterministic machine in polynomial time can also be solved by a non-deterministic machine in polynomial time)]]></description>
</item>
<item>
    <title>Positional Encoding in Transformer</title>
    <link>/posts/20220729-positional_encoding/</link>
    <pubDate>Fri, 19 Aug 2022 23:52:39 -0400</pubDate>
    <author>Jiawei Chen</author>
    <guid>/posts/20220729-positional_encoding/</guid>
    <description><![CDATA[Positional encoding in Transformer criteria Ideally, the following criteria should be satisfied It should output a unique encoding for each time-step Distance between any two time-steps should be consistent across sentences with different lengths out model should generalize to longer sentences without any efforts. Its values should be bounded It must be deterministic Proposed method \[ P(k, 2i) = \sin(\frac{k}{n^{2i/d}}) \] \[ P(k, 2i + 1) = \cos(\frac{k}{n^{2i/d}}) \] k: position of an object input sequence, \(0 \leq k &lt; L/2\) d: Dimension of the output embedding space P(K, j): Position function for mapping a position k in the input sequence to index(k, j) of the positional matrix) n: User defined scalar.]]></description>
</item>
<item>
    <title>Robotics Twist</title>
    <link>/posts/20220814145521-twist/</link>
    <pubDate>Fri, 19 Aug 2022 23:52:39 -0400</pubDate>
    <author>Jiawei Chen</author>
    <guid>/posts/20220814145521-twist/</guid>
    <description><![CDATA[Twist Consider linear and angular velocities of a moving frame. \[ T_{sb }(t) = T(t) = \begin{bmatrix} R(t) &amp; p(t) \\ 0 &amp; 1 \end{bmatrix} \]
Body Twist We also know that pre- or post- multiplying $\dot{R}$ by $(R^{-1})$ results in a representation of the angular velocity vector. Multiply \(\dot{T}\) by \(T^{-1}\)
\begin{align*} T^{-1} \dot{T} &amp;=\left[\begin{array}{cc} R^{\mathrm{T}} &amp; -R^{\mathrm{T}} p \\ 0 &amp; 1 \end{array}\right]\left[\begin{array}{cc} \dot{R} &amp; \dot{p} \\ 0 &amp; 0 \end{array}\right] \\ &amp;=\left[\begin{array}{cc} R^{\mathrm{T}} \dot{R} &amp; R^{\mathrm{T}} \dot{p} \\ 0 &amp; 0 \end{array}\right] \\ &amp;=\left[\begin{array}{cc} \left[\omega_{b}\right] &amp; v_{b} \\ 0 &amp; 0 \end{array}\right] \end{align*}]]></description>
</item>
</channel>
</rss>
